---
title: Gaussian Process Theory 1 - Probability in Infinite Dimensions
subtitle: I begin my discussion of GP theory with a high-level overview of how probability distributions may be defined over function spaces.
layout: default
date: 2024-01-21
keywords: GP, Prob-Theory
published: false
---

# Plan
1. Introductory post (2 views of stochastic process; moving from random variables to
  measure on function space). Background on Borel sets on R and topology on R.
  Review of Caretheodory extension theorem.
2. From Gaussian variable to Gaussian measure. Include product spaces (measure
  and topology) and definition of multivariate Gaussian measure.
3. Push-forward measures and Kolmogorov Extension theorem
4. From finite to countably infinite product spaces: Construct measure on ell_inf
(see Stuart paper and the references therein). Use Kolmogorov extension theorem
to exert the existence of the measure here.
5. A first step towards a Gaussian Measure: Sigma Algebras on function space. First
Borel sigma alg; why it is often too big to work with. Then introduce the cylindrical
sigma algebra and different definitions of cylinder sets.
6. Overcoming tricky Measurability Issues: Radon Measures; discuss why it is
natural to define Gaussian measure on separable Banach space (the Borel and
cylindrical sigma algebras agree - just as they do in the finite dim case).

# Other Notes/Resources
It seems that the procedure to build up a Gaussian measure is to 1.) Define
it on the cylindrical sigma alg; which is typically done by first defining the
finite dimensional dists and then applying Kolmogorov extension theorem,
2.) extending to the Borel sigma algebra in non-separable case (in separable
  case this is equal to the cylindrical sigma alg); this this post:
  https://mathoverflow.net/questions/414826/bayesian-inverse-problems-on-non-separable-banach-spaces

See exercise 3.6 of the SPDE notes for an example of measurability issues in
the case of a non-separable space.


# Introduction
TODO: include motivation of viewing stochastic process as random function
and wanting to define prob dist over functions; i.e. want to talk about the
probability of events that concern the entire sample path.
Also introduce the notion of finite-dim dists.


## Some Background
Developing probability theory in infinite-dimensions builds heavily on existing
results in finite dimensions. We start by reviewing some useful background material
that will be leveraged throughout these notes.

{% katexmm %}
### Borel Sets in $\mathbb{R}$
We recall that a $\sigma$-algebra associated with an arbitrary non-empty set
$\Omega$ is a collection of subsets of $\Omega$ that is closed under
complements, countable unions, and countable intersections. In probability
theory, where $\Omega$ is the sample space containing outcomes of some experiment,
a $\sigma$-algebra defines the events to which we may assign probabilities.
In measure theory, the $\sigma$-algebra is the collection of subsets to which
we may define a consistent notion of *measure* (length, area, volume, etc.).
A very common setting in applications is where $\Omega = \mathbb{R}$
is equipped with the *Borel* $\sigma$-algebra $\mathcal{B}(\mathbb{R})$,
which is the smallest $\sigma$-algebra that contains all of the open sets
in $\mathbb{R}$; we equivalently say that $\mathcal{B}(\mathbb{R})$ is
*generated* by the open sets in $\mathbb{R}$. By *smallest*, we mean that if
$\mathcal{A}$ is an arbitrary $\sigma$-algebra containing all of the open sets
in $\mathbb{R}$, then $\mathcal{A} \subseteq \mathcal{B}(\mathbb{R})$. It can be
shown that any intersection of (perhaps uncountably many) $\sigma$-algebras is
itself a $\sigma$-algebra, and thus the smallest $\sigma$-algebra is equivalently
given by the intersection of all $\sigma$-algebras containing the open sets.
Finally, we note that since any open set in $\mathbb{R}$ can be written (uniquely)
as a countable union of disjoint open intervals, then $\mathcal{B}(\mathbb{R})$
is actually generated just by the collection of open intervals.

### Borel Sets in $\mathbb{R}^N$
If $\Omega = \mathbb{R}^N$ we can similarly define $\mathcal{B}(\mathbb{R}^N)$
as the smallest $\sigma$-algebra containing all open sets of $\mathbb{R}^N$.
Analogously to the open intervals in $\mathbb{R}$, the open rectangles in
$\mathbb{R}^N$ generate $\mathcal{B}(\mathbb{R}^N)$.

### Product $\sigma$-algebras
Suppose we have spaces $\Omega_1, \dots, \Omega_N$ with respective
$\sigma$-algebras $\mathcal{A}_1, \dots, \mathcal{A}_N$. A natural question is
how to leverage this structure to define a $\sigma$-algebra on the
*product space* $\Omega = \Omega_1 \times \cdots \times \Omega_N$. To do so, let's
first define the functions $E_n: \Omega \to \Omega_n$ by
$$
E_n(\omega) = \omega_n, \qquad \omega = (\omega_1, \dots, \omega_N) \in \Omega.
$$
These functions might reasonably be called *projection* or *coordinate* functions
as they take an element in the product space and return the value in the
$n^{\text{th}}$ coordinate (i.e. they "project" onto $\Omega_n$). We can then
define the product $\sigma$-algebra $\mathcal{A}$ as the smallest $\sigma$-algebra
making all of the coordinate functions $\{E_n\}_{n=1}^{N}$ measurable; that is,
for all $B_n \in \mathcal{A}_n$ and all $n = 1, \dots, N$,
$$
E_n^{-1}(B_n) := \{\omega \in \Omega: \omega_n \in B_n\} \in \mathcal{A}.
$$
In other words, $\mathcal{A}$ is the $\sigma$-algebra generated by the
collection of sets $\{E_n^{-1}(B_n)\}_{B_n \in \Omega_n; 1 \leq n \leq N}$.
In the probability context, this is naturally interpreted as requiring that
the marginal distributions are well-defined; e.g. we must be able to assign a
probability to the set of vectors with first entry in $B_1$, which effectively
marginalizes over all of the other entries.

We have already defined the Borel $\sigma$-algebra $\mathcal{B}(\mathbb{R}^N)$
above as the $\sigma$-algebra generated by the open rectangles in
$\mathbb{R}^N$. However, the notion of a product $\sigma$-algebra gives a
second reasonable route to constructing a $\sigma$-algebra on $\mathbb{R}^N$.
In other words, what if we take
$\Omega_n = \mathbb{R}$ and $\mathcal{A}_n = \mathcal{B}(\mathbb{R})$
for all $n$ in the above definition? It turns out that the resulting product
$\sigma$-algebra is equal to $\mathcal{B}(\mathbb{R}^N)$, so the two
constructions are equivalent.  

### From Finite to Infinite Products
In the ensuing notes we will be concerned with the case where the space $\Omega$
is infinite-dimensional. Typically $\Omega$ is a set of functions $f(x)$.
The jump from finite to infinite dimensions is considerably
trickier than the jump from one dimension to a finite product space. However,
some of the core ideas briefly summarized above will still prove useful. In
the subsequent section, we will define a very natural generalization of the
coordinate functions used in constructing the product $\sigma$-algebra. The
concept of a collection of sets generating a $\sigma$-algebra will also be
crucial. Since $\mathcal{B}(\mathbb{R}^N)$ is generated by open rectangles,
one can show that two probability measures on
$(\mathbb{R}^N, \mathcal{B}(\mathbb{R}^N))$ agree if and only if they assign
the same probability to all open rectangles. In infinite dimensions, we will
see that two measures agree if and only if their finite-dimensional marginal
distributions $[f(x_1), \dots, f(x_N)]$ agree. Although the leap to infinite
dimensions results in a bunch of new issues, I find that drawing analogies such
as this to be helpful in motivating some of the subsequent exposition.
{% endkatexmm %}


# Sigma Algebras
{% katexmm %}
We begin quite generically by considering the collection of subsets of functions
to which we will try to assign probabilities in a consistent fashion. To this end,
let $\mathcal{X}$ be an arbitrary non-empty set, which I will refer to as the
**index set**. Ultimately, we will consider this set to be the input space of
a GP, but for now we leave things quite general; we're not even placing any
restrictions on the cardinality of $\mathcal{X}$. Define the function space
$\mathbb{R}^{\mathcal{X}}$ consisting of functions mapping from $\mathcal{X}$ to
$\mathbb{R}$.
As a first step towards defining a probability space of functions, we
consider the problem of constructing a $\sigma$-algebra for
$\mathbb{R}^{\mathcal{X}}$ in this generic setting. We
will be considering two different candidates for a $\sigma$-algebra over
$\mathbb{R}^{\mathcal{X}}$:
1. **Borel**: A natural generalization of the Borel $\sigma$-algebra on $\mathbb{R}$.
2. **Cylindrical**: Which uses the notion of the finite-dimensional distributions
as a building block.

We begin by introducing an important concept: the **evaluation functional**
(a.k.a coordinate functional) $E_x: \mathbb{R}^{\mathcal{X}} \to \mathbb{R}$,
where $x \in \mathcal{X}$ and $E_x$ is defined by
$$
E_x(f) = f(x), \qquad f \in \mathbb{R}^{\mathcal{X}}.
$$
This is a direct generalization of the projection/coordinate function discussed
above.
The name *evaluation functional* is clear, as the map $E_x$ takes in a function
$f$ and simply returns its value at the input $x$. The alternate name
*coordinate function* is remains enlightening in this more general context;
if we loosely think of $f$ as a
(potentially) infinite-dimensional vector, then $E_x(f)$ simply returns the
value in the $x^{\text{th}}$ entry (coordinate) of $f$. If the index set
$\mathcal{X}$ is finite then $f$ really can be defined as a vector and
this reduces to the finite-dimensional product space case discussed above.
Also note that the evaluation functionals are linear since
for $\alpha, \beta \in \mathbb{R}$ and $f, g \in \mathbb{R}^{\mathcal{X}}$,
$$
E_x(\alpha f + \beta g) = (\alpha f + \beta g)(x)
= \alpha f(x) + \beta g(x) = \alpha E_x(f) + \beta E_x(g),
$$
but they are not necessarily continuous. Function spaces for which the evaluation
functionals are continuous are a special, and quite important, case.

## The Cylindrical $\sigma$-Algebra

### Definition Using Marginal Distributions
Without further ado, the cylindrical $\sigma$-algebra is defined below.

**Definition.** The cylindrical $\sigma$-algebra $\mathcal{B}^{\mathcal{X}}$
for the space
$\mathbb{R}^{\mathcal{X}}$ is the smallest $\sigma$-algebra ensuring every
evaluation functional $\{E_x\}_{x \in \mathcal{X}}$ is measurable.

We will spend a while unpacking this. First note that this definition is
essentially identical to that of the product $\sigma$-algebra discussed in the
finite-dimensional case. To be precise, we note that the measurability of
$E_x: \mathbb{R}^{\mathcal{X}} \to \mathbb{R}$ is defined with respect to
the Borel $\sigma$-algebra on $\mathbb{R}$. Recalling the definition of
measurability gives the chain of equivalences
\begin{align}
E_x \text{ is } \mathcal{B}^{\mathcal{X}}\text{-measurable}
&\iff E_x^{-1}(B) \in \mathcal{B}^{\mathcal{X}} &&\forall B \in \mathcal{B}(\mathbb{R}) \newline
&\iff \\{f \in \mathbb{R}^{\mathcal{X}}: f(x) \in B\\} \in \mathcal{B}^{\mathcal{X}} &&\forall B \in \mathcal{B}(\mathbb{R}),
\end{align}
where the final line follows from the definition
of the evaluation functional. It is worthwhile taking a moment to think about
what the set $\{f \in \mathbb{R}^{\mathcal{X}}: f(x) \in B\}$ means. For a fixed
Borel set $B$, it is the set of functions whose value at $x$ lies in the set
$B$. Using the vector analogy, this would correspond to all vectors with
$x^{\text{th}}$ element falling in the set $B$. We recall that the
 $\sigma$-algebra will ultimately define the subsets of functions to which
 we will assign probabilities; i.e. the sets we will be able to measure. Thus,
 the definition of the cylindrical $\sigma$-algebra ensures the following: if we
 are able to answer the question

<div style="text-align: center;">
 What is the probability that a scalar is in the set $B$?
</div>

 then we must also be able to answer the question

 <div style="text-align: center;">
  What is the probability of a function whose value $f(x)$ is in the set $B$?
 </div>

Moreover, this must be true for all Borel sets $B$ and indices
$x \in \mathcal{X}$. So the definition of the cylindrical $\sigma$-algebra
is really ensuring that all of the univariate marginal distributions are
well-defined, just as in the finite-dimensional case.
Being able to answer the second question above effectively means that we are
able to marginalize over all other functions in order to find the
probability of a function with $f(x) \in B$. In other words, we're
marginalizing over the (potentially infinitely many) other coordinates in
$\mathcal{X}$ in order to find a marginal probability that involves a constraint
at the single coordinate $x$.

### Cylinder Sets
Okay, so the definition ensures that the univariate marginal distributions make
sense. But what about the other finite-dimensional distributions? In other words,
what if we impose constraints at a finite set of coordinates
$x_1, \dots, x_N$? The properties of $\sigma$-algebras ensure that the requirement
on the univariate marginals is enough to impose the same logic on all
finite-dimensional distributions. Indeed, consider
$$
\{f \in \mathbb{R}^{\mathcal{X}} : f(x_1) \in B_1, \dots, f(x_N) \in B_N\}, \tag{1}
$$
where $B_1, \dots, B_N$ are all Borel sets. Analogously to the univariate marginals,
this is a set to which we *should* be able to assign a probability. This is
indeed guaranteed since the set can be written as the intersection
$$
\{f \in \mathbb{R}^{\mathcal{X}} : f(x_1) \in B_1, \dots, f(x_N) \in B_N\}
= \bigcap_{n=1}^{N} E_{x_n}^{-1}(B_n).
$$
By definition of the cylindrical $\sigma$-algebra, each $E_{x_n}^{-1}(B_n)$ is
measurable (i.e. contained in the $\sigma$-algebra) and thus so is the above set
since $\sigma$-algebras are closed under finite intersections. With this
established, we conclude that the cylindrical $\sigma$-algebra ensures that
all **finite-dimensional** distributions are well-defined. The concept of
finite-dimensional distributions plays a crucial role in the development of
probability in infinite-dimensions, and hence so do sets of the form (1).
We call sets of this form **cylinder sets** (which is from where the cylindrical
$\sigma$-algebra derives its name). To be more precise, we define a cylinder
set as a set of the form
\begin{align}
&\\{f \in \mathbb{R}^{\mathcal{X}} : [f(x_1), \dots, f(x_N)] \in B\\}, \tag{2} \newline
&B \in \mathcal{B}(\mathbb{R}^N),
\qquad x_n \in \mathcal{X},
\qquad N \in \mathbb{N}
\end{align}
The entire collection of cylinder
sets is defined by varying $N \in \mathbb{N}$, $x_1, \dots, x_N \in \mathcal{X}$,
and $B \in \mathcal{B}(\mathbb{R}^N)$.
Varying these parameters defines the family of sets of functions $f$ resulting
from imposing constraints on the function values at finitely many inputs
(specifically just constraints involving Borel sets). By the product
$\sigma$-algebra definition of $\mathcal{B}(\mathbb{R}^N)$, a set
$B \in \mathcal{B}(\mathbb{R}^N)$ can be written using complements,
countable unions, and countable intersections of sets of the form
$E_{x_n}^{-1}(B)$, $n \in \{1, \dots, N\}$, $B \in \mathcal{B}(\mathbb{R})$ so
the cylindrical $\sigma$-algebra also contains the cylinder sets as given by
the slightly more general definition in (2).


### Summarizing Equivalent Definitions


### Example: Finite Index Set
{% endkatexmm %}


# Resources
1. Dan Simpson blog on Gaussian processes
2. Notes on Sigma Algebras for Brownian Motion Course (Ron Peled)
3. Analysis and Probability on Infinite-Dimensional Spaces (Nathaniel Eldredge)
4. Structure Theorem for Gaussian Measures (Wikipedia)
5. Andrew Stuart (both manuscripts on Bayesian inverse problems)
6. Lecture 2: Gaussian Measures in infinite-dimensions
7. Background notes to course 'stochastic processes' Spring 2013
